\section{Introduction}
\label{section:introduction}

Exploration is a key capability that enables robotic vehicles to operate in unknown environments.
In general, the shortest trajectory over which a robot can greedily explore an environment is the trajectory formed by choosing actions which maximally reduce uncertainty in the environmental belief representation, or map.
One strategy to accomplish this is to choose control actions that maximize the expected mutual information between the robot's map at a future timestep and the robot's current map.
This solution is one variant of a broad category of exploration strategies known as active Simultaneous Localization and Mapping (SLAM) \cite{thrun2005probabilistic}.

State of the art active SLAM implementations generally only compute actions over a one-step planning horizon due to the extremely high computational cost of determining expected mutual information over all potential future locations \cite{bourgault2002information}, \cite{stachniss2005information}.
However, plans over much longer horizons can be generated if these expected mutual information values can be computed once, cached, and updated efficiently based on new information.
An even more efficient approach would utilize sparse planning graphs to limit expected mutual information calculations to a select few feasible future locations in the map.
Rapidly Exploring Random Trees (RRT) and lattice graphs are two examples of sparse planning graphs which decompose the reachable space into a sparse set of goal states based on a set of motion primitives for planning purposes.

This project seeks to develop a recursive formulation for efficiently and intelligently updating expected mutual information over a finite horizon as the robot moves through an unknown environment and builds a map from sensor observations.

% TODO: say what each of the sections in this report will be about? e.g. In Section \ref{section:occupancy_grid_mapping} we provide a brief overview of how a map is constructed from sensor observations, Section \ref ... etc

\section{Occupancy Grid Mapping}
\label{section:occupancy_grid_mapping}

We represent the map as an occupancy grid, which consists of a set of cells: $m = \{m^{i}\}_{i=1}^{N}$.
The probability that an individual cell is occupied is given by $p\left(m^{i} \ \vert \ x_{1:t}, z_{1:t}\right)$, where $x_{1:t}$ denotes the history of states of the vehicle, and $z_{1:t}$ denotes the history of range observations accumulated by the vehicle.
We assume that cell occupancy probabilities are independent of one another: $p\left(m \ \vert \ x_{1:t}, z_{1:t}\right) = \prod_{i} p\left(m^{i} \ \vert \ x_{1:t}, z_{1:t}\right)$.
For notational simplicity we write the map conditioned on random variables $x_{1:t}$ and $z_{1:t}$ as $p_{t}\left(m\right) := p\left(m \ \vert \ x_{1:t}, z_{1:t}\right)$.
Additionally, unobserved grid cells are assigned a uniform prior of being occupied.

We represent the occupancy status of grid cell $m^i$ at time $t$ with a log odds expression
\begin{align}
  l_t &:= \log \frac{p \left( m^i \ \vert \ z_{1:t} \right)}{p \left( \bar{m}^i \ \vert \ z_{1:t} \right)}
\end{align}
, where $\bar{m}^i$ denotes the probability that $m^i$ is unoccupied.
When a new observation $z_t$ is obtained, the log odds update is given by
\begin{align}
  l_t &= l_{t-1} + \log \frac{p\left( m^i \ \vert \ z_t \right)}{p \left( m^i \right)} - \log \frac{p\left( \bar{m}^i \ \vert \ z_t \right)}{p \left(\bar{m}^i \right)}
\end{align}
where the last two terms represent the inverse sensor model.
