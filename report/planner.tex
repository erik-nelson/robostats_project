\section{Closed Loop RRTs}
\label{sec:planner}

To make use of this information cost function to guide exploration, we consider a sampling-based planning approach that can evaluate the predicted information gain throughout the environment. In addition, we wish to use the occupancy grid that is being updated online (as described in Sect.~\ref{section:occupancy_grid_mapping}) to guide the vehicle around obstacles in the environment. The rapidly-exploring random tree (RRT) algorithm is well suited to planning paths through these types of large environments, and works as follows.
The planner starts from the vehicle's current state and samples a point $x$ in the environment. Using the occupancy grid, we can reject samples that lie in cells with a sufficiently high probability of being occupied. If the sample is valid, we find the closest node in the tree of paths (initially just the vehicle state), where closeness is measured in terms of Euclidean distance, and add a new edge to the tree connecting the sample point to the nearest node.
Then a new sample is drawn and the process repeats to grow a tree of path segments through the environment. This tree-growing process terminates after a specified time, and the minimum cost path is returned.

Figure~\ref{fig:} shows snapshots of the system planning through the environment while updating the occupancy grid. The edges in the tree are smooth since they are generated by forward simulating the closed-loop vehicle dynamics toward the sample point, resulting in a variant of the RRT algorithm known as Closed-loop RRT (CL-RRT)~\cite{Kuwata09_TCST}. This approach is traditionally used to ensure dynamic feasibility and dense collision checking. However, the forward simulation also means we have full state information for the system at the end of each segment. This allows us to evaluate the predicted information gain at that point and assign a corresponding cost to candidate trajectory.

To change CL-RRT from a goal-directed planner to an exploration-driven planner, we first define the sampling distribution to be a Gaussian centered about the root of the tree, with no bias toward any direction (unlike standard sampling-based planners that will sample the goal some small probability). We also define the cost of each branch segment to just be the information metric computed at its endpoint (as opposed to a more traditional setup where the cost is the total distance traveled from the root plus a cost to go based on an admissible heuristic, such as Euclidean distance to a goal). Finally, since there is no goal to guide the selection of the best branch from the tree, we simply select the branch with the minimum cost endpoint in the entire tree. This enables the planner to compute paths that aim to maximize the predicted information gain.

Define $\mathcal{X}_\text{free}$ to be the space spanned by the unoccupied cells in the occupancy grid.

\begin{algorithm}
\caption{CL-RRT: Tree Expansion}
\label{alg:clrrt_expansion}
\begin{algorithmic}[1]
\State Sample point $x_s$ from the environment
\State Select min-cost node from $n$ nearest in tree
\State $k \gets 0$
\State $\hat{x}(t+k) \gets $ last state at n
\While{$\hat{x}(t+k) \in \mathcal{X}_\text{free}(t+k)$ and $\hat{x}(t+k) \neq x_s$}
	\State Compute control input to drive system to $x_s$
	\State Forward simulate system dynamics
	\State Compute next state $\hat{x}(t+k+1)$ from propagation model
	\State $k \gets k+1$
\EndWhile
$N \gets r_final$
\For{each feasible node $N$ produced}
	\State Update cost estimates for $N$
	\State Add $N$ to tree
\EndFor
\end{algorithmic}
\end{algorithm}
